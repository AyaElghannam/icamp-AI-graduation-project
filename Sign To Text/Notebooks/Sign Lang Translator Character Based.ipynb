{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.python.client import device_lib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path1 = r\"AllData\\Characters\\Peter\\Characters_Dataset\"\n",
    "dataset_path2 = r\"AllData\\Characters\\Aya\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [ 'aleff',  'bb', 'ta', 'thaa', 'jeem', 'haa', 'khaa', 'dal', 'thal', 'ra', \\\n",
    "         'zay' , 'seen', 'sheen',  'saad', 'dhad','taa', 'dha', 'ain', 'ghain','fa', \\\n",
    "          'gaaf', 'kaaf','laam', 'meem', 'nun', 'ha', 'waw','ya']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = image_dataset_from_directory(dataset_path1,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=32,\n",
    "                                             image_size=(224,224),color_mode='rgb',label_mode= 'categorical',\n",
    "                                             class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = image_dataset_from_directory(dataset_path2,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=32,\n",
    "                                             image_size=(224,224),color_mode='rgb',label_mode= 'categorical',\n",
    "                                             class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 2 Datasets\n",
    "dataset = dataset1.concatenate(dataset2)\n",
    "# Get No. of Batches\n",
    "tf.data.experimental.cardinality(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to Training and Validation\n",
    "dataset_batches = tf.data.experimental.cardinality(dataset)\n",
    "# 30% of Data To Validation and Testing\n",
    "validation_dataset = dataset.take(dataset_batches // 7)\n",
    "# 70% of Data To Training\n",
    "training_dataset = dataset.skip(dataset_batches // 7) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Validation to valid and test\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "testing_dataset = validation_dataset.take(val_batches // 2)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Increase up Feeding Data To Network\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "training_dataset = training_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "testing_dataset = testing_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display The No. of Batches \n",
    "print(tf.data.experimental.cardinality(training_dataset))\n",
    "print(tf.data.experimental.cardinality(validation_dataset))\n",
    "print(tf.data.experimental.cardinality(testing_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Initialize Data Augmentation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Layer for Brightness and Contrast\n",
    "class RandomColorDistortion(tf.keras.layers.Layer):\n",
    "    def __init__(self, contrast_range=[0.6, 1.8], \n",
    "                 brightness_delta=[-0.3, 0.3], **kwargs):\n",
    "        super(RandomColorDistortion, self).__init__(**kwargs)\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_delta = brightness_delta\n",
    "    \n",
    "    def call(self, images, training=True):\n",
    "        if not training:\n",
    "            return images\n",
    "        \n",
    "        contrast = np.random.uniform(\n",
    "            self.contrast_range[0], self.contrast_range[1])\n",
    "        brightness = np.random.uniform(\n",
    "            self.brightness_delta[0], self.brightness_delta[1])\n",
    "        \n",
    "        images = tf.image.adjust_contrast(images, contrast)\n",
    "        images = tf.image.adjust_brightness(images, brightness)\n",
    "        images = tf.clip_by_value(images, 0, 255)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation Layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # Make a Random Rotation\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.05),\n",
    "    # Make a Random Width\n",
    "    tf.keras.layers.RandomWidth((-.2,.2), interpolation='bilinear'),\n",
    "    # Make a Random Height\n",
    "    tf.keras.layers.RandomHeight((-.2,.2), interpolation='bilinear'),\n",
    "    # Make a Random Translation\n",
    "    tf.keras.layers.RandomTranslation((-0.1, 0.1),(-0.1, 0.1),fill_mode='constant'),\n",
    "    # Resize image to 224 x 224 pixels again after Widthing,Heighting\n",
    "    tf.keras.layers.Resizing(224,224,interpolation='bilinear'),\n",
    "    # Make a Random Color\n",
    "    RandomColorDistortion()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show The Output of Augmentation Layer for Same Image\n",
    "for image, _ in training_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Base Network\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Conv Layer\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build a Network for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Network for Training \n",
    "inp = layers.Input(shape=(224,224,3))\n",
    "x = data_augmentation(inp)\n",
    "x = (conv_base)(inp)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outs = layers.Dense(len(classes), activation='softmax')(x)\n",
    "model = models.Model(inputs=inp, outputs=[outs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs/vgg16_transfer_learning')\n",
    "tb_callback = TensorBoard(log_dir=log_dir,histogram_freq=1,\n",
    "                          update_freq='epoch',\n",
    "                          profile_batch=0) ## !tensorboard --logdir=.\n",
    "mc = ModelCheckpoint('Models/vgg16_transfer_learning.h5', monitor='val_acc', mode='max', verbose=1,save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1,patience=5)\n",
    "callbacks = [tb_callback,mc,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_dataset,epochs=50,callbacks=[callbacks], validation_data = validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save The Last Model\n",
    "model.save('Models/last_training_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testing_dataset) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0ab8c99b4bfaa44da2c5b935dbf33e7e1f6d7633e1a18625ce6d59279f815e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('TF2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
